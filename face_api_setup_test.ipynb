{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from io import BytesIO\n",
    "# To install this module, run:\n",
    "# python -m pip install Pillow\n",
    "from PIL import Image, ImageDraw\n",
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from azure.cognitiveservices.vision.face.models import TrainingStatusType, Person, QualityForRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person group: user_william_test\n",
      "face 3d70cbcf-3850-4135-9598-a288da3da349 added to person 680d256b-ba62-4afc-9396-b1e77e286e7d\n",
      "face 24ac1001-1acf-4ba2-b349-5a5cbabc11d3 added to person 680d256b-ba62-4afc-9396-b1e77e286e7d\n"
     ]
    }
   ],
   "source": [
    "# This key will serve all examples in this document.\n",
    "KEY = # use env variable / copy from azure portal\n",
    "\n",
    "# This endpoint will be used in all examples in this quickstart.\n",
    "ENDPOINT = # use env variable / copy from azure portal\n",
    "\n",
    "# Base url for the Verify and Facelist/Large Facelist operations\n",
    "IMAGE_BASE_URL = 'https://raw.githubusercontent.com/van-william/azure-face-api/main/images/'\n",
    "\n",
    "# Used in the Person Group Operations and Delete Person Group examples.\n",
    "# You can call list_person_groups to print a list of preexisting PersonGroups.\n",
    "# SOURCE_PERSON_GROUP_ID should be all lowercase and alphanumeric. For example, 'mygroupname' (dashes are OK).\n",
    "PERSON_GROUP_ID = 'user_william_test' #str(uuid.uuid4()) # assign a random ID (or name it anything)\n",
    "\n",
    "# Used for the Delete Person Group example.\n",
    "# TARGET_PERSON_GROUP_ID = str(uuid.uuid4()) # assign a random ID (or name it anything)\n",
    "\n",
    "# Create an authenticated FaceClient.\n",
    "face_client = FaceClient(ENDPOINT, CognitiveServicesCredentials(KEY))\n",
    "\n",
    "'''\n",
    "Create the PersonGroup\n",
    "'''\n",
    "# Create empty Person Group. Person Group ID must be lower case, alphanumeric, and/or with '-', '_'.\n",
    "print('Person group:', PERSON_GROUP_ID)\n",
    "face_client.person_group.create(person_group_id=PERSON_GROUP_ID, name=PERSON_GROUP_ID, recognition_model='recognition_04')\n",
    "\n",
    "# Define user to login friend\n",
    "user_login = face_client.person_group_person.create(PERSON_GROUP_ID, name=\"William\")\n",
    "\n",
    "'''\n",
    "Detect faces and register them to each person\n",
    "'''\n",
    "# Find all jpeg images of friends in working directory (TBD pull from web instead)\n",
    "user_login_images = [f'{IMAGE_BASE_URL}/william vanbuskirk-headshot-3.jpg', f'{IMAGE_BASE_URL}/william.png']\n",
    "\n",
    "# Add to user profile\n",
    "for image in user_login_images:\n",
    "    # Check if the image is of sufficent quality for recognition.\n",
    "    sufficientQuality = True\n",
    "    detected_faces = face_client.face.detect_with_url(url=image, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "    for face in detected_faces:\n",
    "        if face.face_attributes.quality_for_recognition != QualityForRecognition.high:\n",
    "            sufficientQuality = False\n",
    "            break\n",
    "        face_client.person_group_person.add_face_from_url(PERSON_GROUP_ID, user_login.person_id, image)\n",
    "        print(\"face {} added to person {}\".format(face.face_id, user_login.person_id))\n",
    "\n",
    "    if not sufficientQuality: continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pg resource is user_william_test\n",
      "<msrest.pipeline.ClientRawResponse object at 0x10926d2d0>\n",
      "Training status: running.\n",
      "\n",
      "Training status: succeeded.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Train PersonGroup\n",
    "'''\n",
    "# Train the person group\n",
    "print(\"pg resource is {}\".format(PERSON_GROUP_ID))\n",
    "rawresponse = face_client.person_group.train(PERSON_GROUP_ID, raw= True)\n",
    "print(rawresponse)\n",
    "\n",
    "while (True):\n",
    "    training_status = face_client.person_group.get_training_status(PERSON_GROUP_ID)\n",
    "    print(\"Training status: {}.\".format(training_status.status))\n",
    "    print()\n",
    "    if (training_status.status is TrainingStatusType.succeeded):\n",
    "        break\n",
    "    elif (training_status.status is TrainingStatusType.failed):\n",
    "        face_client.person_group.delete(person_group_id=PERSON_GROUP_ID)\n",
    "        sys.exit('Training the person group has failed.')\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pausing for 10 seconds to avoid triggering rate limit on free account...\n",
      "[<azure.cognitiveservices.vision.face.models._models_py3.DetectedFace object at 0x10929a4d0>]\n",
      "6d9c4b7a-a4d1-44d6-9bba-5c4857e411ce\n",
      "verification result: True. confidence: 0.95414\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Identify a face against a defined PersonGroup\n",
    "'''\n",
    "# Group image for testing against\n",
    "test_image = 'https://raw.githubusercontent.com/van-william/azure-face-api/main/test_images/william_test.jpeg'\n",
    "\n",
    "print('Pausing for 10 seconds to avoid triggering rate limit on free account...')\n",
    "time.sleep (10)\n",
    "\n",
    "# Detect faces\n",
    "#face_id = []\n",
    "# We use detection model 3 to get better performance, recognition model 4 to support quality for recognition attribute.\n",
    "faces = face_client.face.detect_with_url(test_image, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "print(faces)\n",
    "for face in faces:\n",
    "    # Only take the face if it is of sufficient quality.\n",
    "    if face.face_attributes.quality_for_recognition == QualityForRecognition.high or face.face_attributes.quality_for_recognition == QualityForRecognition.medium:\n",
    "        face_id = face.face_id\n",
    "        print(face_id)\n",
    "\n",
    "verify_result = face_client.face.verify_face_to_person(face_id= face_id, person_id=user_login.person_id, person_group_id=PERSON_GROUP_ID)\n",
    "print('verification result: {}. confidence: {}'.format(verify_result.is_identical, verify_result.confidence))\n",
    "\n",
    "\n",
    "# Identify faces\n",
    "#results = face_client.face.identify(face_ids, PERSON_GROUP_ID)\n",
    "# print('Identifying faces in image')\n",
    "# if not results:\n",
    "#     print('No person identified in the person group')\n",
    "# for identifiedFace in results:\n",
    "#     if len(identifiedFace.candidates) > 0:\n",
    "#         print('Person is identified for face ID {} in image, with a confidence of {}.'.format(identifiedFace.face_id, identifiedFace.candidates[0].confidence)) # Get topmost confidence score\n",
    "\n",
    "#         # Verify faces\n",
    "#         verify_result = face_client.face.verify_face_to_person(identifiedFace.face_id, identifiedFace.candidates[0].person_id, PERSON_GROUP_ID)\n",
    "#         print('verification result: {}. confidence: {}'.format(verify_result.is_identical, verify_result.confidence))\n",
    "#     else:\n",
    "#         print('No person identified for face ID {} in image.'.format(identifiedFace.face_id))\n",
    " \n",
    "\n",
    "# print()\n",
    "# print('End of quickstart.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6d9c4b7a-a4d1-44d6-9bba-5c4857e411ce\n",
      "680d256b-ba62-4afc-9396-b1e77e286e7d\n",
      "user_william_test\n"
     ]
    }
   ],
   "source": [
    "print(face_id)\n",
    "print(user_login.person_id)\n",
    "print(PERSON_GROUP_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
